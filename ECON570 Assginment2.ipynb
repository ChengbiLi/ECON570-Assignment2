{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc8f6c2",
   "metadata": {},
   "source": [
    "# ECON570 Assignment 2\n",
    "### Import and Definition preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b5103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import graphviz as gr\n",
    "from tqdm import tqdm\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5093991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dec7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f694d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err # outcome equation\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n",
    "    \n",
    "    # regression discontinuity\n",
    "#     W = W0 + 0.5*C+3*X[:,80].reshape([N,1])-6*X[:,81].reshape([N,1])\n",
    "#     treated = 1*(W>0)\n",
    "#     Yrdd = 1.2* treated - 4*W + X@beta0 +0.6*C+err\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    \"\"\"\n",
    "    tau - treatment effect\n",
    "    Nrange - rage of sample sizes\n",
    "    p - number of covariates genrated\n",
    "    p0 - number of covariates included\n",
    "    corr - correlation between covariates\n",
    "    conf - confounder\n",
    "    \n",
    "    \"\"\"\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n",
    "\n",
    "\n",
    "def fn_plot_with_ci(n_values,tauhats,tau,lb,ub,caption):\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    plt.plot(n_values,tauhats,label = '$\\hat{\\\\tau}$')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('$\\hat{\\\\tau}$')\n",
    "    plt.axhline(y=tau, color='r', linestyle='-',linewidth=1,\n",
    "                label='True $\\\\tau$={}'.format(tau))\n",
    "    plt.title('{}'.format(caption))\n",
    "    plt.fill_between(n_values, lb, ub,\n",
    "        alpha=0.5, edgecolor='#FF9848', facecolor='#FF9848',label = '95% CI')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3d234",
   "metadata": {},
   "source": [
    "## 1.Simulate a DGP where the outcome of interest depends on a randomly assigned treatment and some observed covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a755274",
   "metadata": {},
   "source": [
    "### Simulate a DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d6d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 6\n",
    "p0 = 0 \n",
    "flagX = 1\n",
    "N = 1000\n",
    "Nrange = range(100,1000,2)\n",
    "Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "data = np.concatenate([Y,T,X],axis = 1 )\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['Y', 'T', 'X1', 'X2','X3','X4','X5','X6']\n",
    "data.to_csv('data_covariates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f161e7",
   "metadata": {},
   "source": [
    "### Illustrate the DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccbf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M35.7146,-72.5708C39.9597,-64.0807 45.1536,-53.6929 49.8663,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"53.024,-45.7782 54.3657,-35.2687 46.763,-42.6477 53.024,-45.7782\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.2854,-72.5708C86.0403,-64.0807 80.8464,-53.6929 76.1337,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.237,-42.6477 71.6343,-35.2687 72.976,-45.7782 79.237,-42.6477\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fee9b582850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ceb78",
   "metadata": {},
   "source": [
    "### Monte Carlo experiment with sample sizes N=100 and N=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0300f",
   "metadata": {},
   "source": [
    "#### a.Do not control for any covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efa251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2969.23it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:10<00:00, 196.95it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "        Yt = Y[np.where(T==1)[0],:]\n",
    "        Yc = Y[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ebb486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.005828010781573024, RMSE=0.20130962447967196, size=0.055\n",
      "N=1000: bias=-0.0029570154724705873, RMSE=0.06296158185741106, size=0.052\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cafecc",
   "metadata": {},
   "source": [
    "#### b.Control for all the covariates that affect the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5edc7fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:02<00:00, 943.08it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:12<00:00, 156.80it/s]\n"
     ]
    }
   ],
   "source": [
    "p0 = 6\n",
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d3065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.00672389859428636, RMSE=0.1445534792654984, size=0.055\n",
      "N=1000: bias=-0.0020096601393059864, RMSE=0.04415564176515236, size=0.0515\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6308ba",
   "metadata": {},
   "source": [
    "### Real-life situation that might be consistent with the DGP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97889051",
   "metadata": {},
   "source": [
    "#### X: Class size\n",
    "#### T: Whether the whole class receive addtional training\n",
    "#### Y: Average score of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc7fe2",
   "metadata": {},
   "source": [
    "## 2.Simulate a DGP with a confounder (common cause)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfa13b",
   "metadata": {},
   "source": [
    "### Simulate a DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ecd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_conf(tau,N,p,corr):\n",
    "\n",
    "    nvar = p+1\n",
    "    corr = 0.5\n",
    "    X = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = X[:,1].reshape([N,1])\n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    Yab = tau*T+0.5*C+err\n",
    "    Tab = T+0.5*C\n",
    "\n",
    "    return (Yab,Tab,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91288c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "p = 6\n",
    "N = 1000\n",
    "Y,T,X = fn_generate_data_conf(tau,N,p,corr)\n",
    "data = np.concatenate([Y,T,X],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['Y', 'T', 'X']\n",
    "data.to_csv('data_confounder.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf9c8b",
   "metadata": {},
   "source": [
    "### Illustrate the DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9137cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">T</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;T -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;T</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3258,-144.2022C44.2524,-136.0064 40.5384,-126.1024 37.1305,-117.0145\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"40.3858,-115.7274 33.5974,-107.593 33.8315,-118.1853 40.3858,-115.7274\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57.7474,-144.0931C59.7466,-133.6241 61.9966,-120.1241 63,-108 64.3197,-92.0545 64.3197,-87.9455 63,-72 62.2945,-63.4753 60.9727,-54.2703 59.5551,-45.917\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"62.9689,-45.1258 57.7474,-35.9069 56.0803,-46.3698 62.9689,-45.1258\"/>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.6742,-72.2022C36.7476,-64.0064 40.4616,-54.1024 43.8695,-45.0145\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47.1685,-46.1853 47.4026,-35.593 40.6142,-43.7274 47.1685,-46.1853\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fee9b57f610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"T\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c721df",
   "metadata": {},
   "source": [
    "### Monte Carlo experiment with sample sizes N=100 and N=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b02e4d",
   "metadata": {},
   "source": [
    "#### a.Fail to control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad362e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1531.55it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:10<00:00, 188.62it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_conf(tau,N,p,corr)\n",
    "        covars = np.concatenate([T],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a21c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.32060242454345766, RMSE=0.3533762907506241, size=0.7125\n",
      "N=1000: bias=-0.32391299770732046, RMSE=0.33809001221519336, size=0.9825\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ce1d7",
   "metadata": {},
   "source": [
    "#### b.Control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccb82962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1465.52it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:11<00:00, 178.37it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_conf(tau,N,p,corr)\n",
    "        const = np.ones([N,1])\n",
    "        covars = np.concatenate([T,X],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d8071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.00282495213435412, RMSE=0.14271067974275373, size=0.054\n",
      "N=1000: bias=0.0002491273383675193, RMSE=0.04419806590295818, size=0.055\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5f24e",
   "metadata": {},
   "source": [
    "### Real-life situation that might be consistent with the DGP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738b303",
   "metadata": {},
   "source": [
    "#### X: Intelligence quotient\n",
    "#### T: Whether accept graduate education\n",
    "#### Y: Hourly wage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa409b",
   "metadata": {},
   "source": [
    "## 3.Simulate a DGP with selection bias into the treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0606f",
   "metadata": {},
   "source": [
    "### Simulate a DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441fddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_sele(tau,N,p,corr):\n",
    "\n",
    "    nvar = p+1 \n",
    "    corr = 0.5 \n",
    " \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "     \n",
    "    T = fn_randomize_treatment(N)\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    U = np.random.normal(0,1,[N,1])\n",
    "    Y = tau*T+err\n",
    "    X = 0.25*T+0.71*Y+U\n",
    "\n",
    "    return (Y,T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fbe3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "p = 6\n",
    "N = 1000\n",
    "Y,T,X = fn_generate_data_sele(tau,N,p,corr)\n",
    "data = np.concatenate([Y,T,X],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['Y', 'T', 'X']\n",
    "data.to_csv('data_selectionbias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bef982",
   "metadata": {},
   "source": [
    "### Illustrate the DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e4ec4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"90pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 90.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 86,-184 86,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M23.6685,-144.0736C21.8913,-133.5982 19.8913,-120.0982 19,-108 17.8244,-92.0432 17.8244,-87.9568 19,-72 19.6267,-63.4935 20.8015,-54.2939 22.0616,-45.9399\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"25.5398,-46.3546 23.6685,-35.9264 18.6282,-45.2455 25.5398,-46.3546\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"55\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.778,-144.5708C36.9872,-136.3187 40.8935,-126.2738 44.4758,-117.0623\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"47.8248,-118.1069 48.1874,-107.5182 41.3008,-115.5697 47.8248,-118.1069\"/>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Y&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.222,-72.5708C45.0128,-64.3187 41.1065,-54.2738 37.5242,-45.0623\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"40.6992,-43.5697 33.8126,-35.5182 34.1752,-46.1069 40.6992,-43.5697\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fee681a7790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"X\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"Y\", \"X\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd95ff",
   "metadata": {},
   "source": [
    "### Monte Carlo experiment with sample sizes N=100 and N=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7af60f",
   "metadata": {},
   "source": [
    "#### a.Control for the variable in between the path from cause to effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a42ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 3262.58it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:10<00:00, 195.45it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_sele(tau,N,p,corr)   \n",
    "        Yt = Y[np.where(T==1)[0],:]\n",
    "        Yc = Y[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47405f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0033737081837509368, RMSE=0.2024904259597893, size=0.0595\n",
      "N=1000: bias=1.6856115816044515e-05, RMSE=0.06258856673498599, size=0.0465\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ddd86",
   "metadata": {},
   "source": [
    "#### b.Do not control for the variable in between the path from cause to effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d291ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1314.32it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:11<00:00, 174.58it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_sele(tau,N,p,corr)\n",
    "        covars = np.concatenate([T,X],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c48254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.7814981031681411, RMSE=0.7986125014543177, size=0.997\n",
      "N=1000: bias=-0.7867243989599613, RMSE=0.7883429723753441, size=1.0\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaf437",
   "metadata": {},
   "source": [
    "### Give an example of a real-life situation that might be consistent with the DGP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f474a6",
   "metadata": {},
   "source": [
    "#### X: Annual expenditure\n",
    "#### T: Whether get surgery this year\n",
    "#### Y: Medical expenditure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81c419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
